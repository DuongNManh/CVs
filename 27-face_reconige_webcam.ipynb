{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Fc85sCzEYiQ"
   },
   "source": [
    "# **Face Recognition on the webcam**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(img_path, save_dir=None):\n",
    "    gray_img = None  \n",
    "    valid_exts = ('.jpg', '.jpeg', '.png', '.bmp')\n",
    "\n",
    "    if os.path.isfile(img_path) and img_path.lower().endswith(valid_exts):\n",
    "        # Load the image with PIL\n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray_img = img.convert(\"L\")\n",
    "\n",
    "        # Convert PIL image to NumPy array for OpenCV display\n",
    "        gray_np = np.array(gray_img)\n",
    "\n",
    "        # Show the image using OpenCV\n",
    "        cv2.imshow(\"Grayscale Image\", gray_np)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        # Save the image if save_dir is provided\n",
    "        if save_dir:\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            filename = os.path.basename(img_path)\n",
    "            save_path = os.path.join(save_dir, filename)\n",
    "            gray_img.save(save_path)\n",
    "\n",
    "    return gray_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = 'C:/Users/Admin/Documents/CVs/img/me/face/'\n",
    "target_dir = 'C:/Users/Admin/Documents/CVs/img/me/face/gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [os.path.join(source_dir, f) \n",
    "         for f in os.listdir(source_dir) \n",
    "         if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "\n",
    "for path in paths:\n",
    "    convert_to_grayscale(path, target_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model to get the face\n",
    "folder_path = 'C:/Users/Admin/Documents/CVs/img/me/face/gray'\n",
    "\n",
    "def get_img_data():\n",
    "  valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
    "  paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path)]\n",
    "  ids = []\n",
    "  faces = []\n",
    "  for path in paths:\n",
    "    if os.path.isfile(path) and path.lower().endswith(valid_exts):\n",
    "      img = Image.open(path).convert('L') # L is single scale color image\n",
    "      img_np = np.array(img, 'uint8')\n",
    "      # Assign a fixed ID (e.g., 1) to all images\n",
    "      id = 1\n",
    "      ids.append(id)\n",
    "      faces.append(img_np)\n",
    "\n",
    "  return np.array(ids), faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the faces and id of the faces\n",
    "ids, faces = get_img_data()\n",
    "\n",
    "# create classifier instance and input training model to output\n",
    "lbph_classifier = cv2.face.LBPHFaceRecognizer_create()\n",
    "lbph_classifier.train(faces, ids)\n",
    "lbph_classifier.write('lbph_classifier.yml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# khởi tạo Haar Cascase Classifier nhận diện khuôn mặt\n",
    "face_detector = cv2.CascadeClassifier('./data/haarcascade_frontalface_default.xml')\n",
    "# # khởi tạo HCC nhận diện mắt\n",
    "# eye_cascade = cv2.CascadeClassifier('data/haarcascade_eye_tree_eyeglasses.xml')\n",
    "# # khởi tạo HCC nhận diện miệng\n",
    "# smile_cascade = cv2.CascadeClassifier('data/haarcascade_smile.xml')\n",
    "\n",
    "face_recognizer= cv2.face.LBPHFaceRecognizer_create()\n",
    "face_recognizer.read('data/lbph_classifier.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height = 220, 200\n",
    "font =cv2.FONT_HERSHEY_COMPLEX_SMALL\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while (True):\n",
    "    con, image = camera.read()\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    detections = face_detector.detectMultiScale(img_gray, scaleFactor=1.2, minNeighbors=3, minSize=(30, 30))\n",
    "    for (x,y,w,h) in detections:\n",
    "        img_face = cv2.resize(img_gray[y:y + w, x:x + h], (width, height))\n",
    "        cv2.rectangle(image, (x,y), (x+w,y+h), (0,255,0), 2)\n",
    "        id, confi = face_recognizer.predict(img_face)\n",
    "        name = \"\"\n",
    "        if id == 1:\n",
    "            name = 'Duong'\n",
    "        elif id == 2:\n",
    "            name = 'Phuc'\n",
    "        cv2.putText(image, name,  (x,y + (w+30)), font, 2, (0,0,255))\n",
    "        cv2.putText(image, str(confi),  (x,y + (h+50)), font, 1, (255,0,255))\n",
    "\n",
    "    cv2.imshow(\"Face\", image)\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
