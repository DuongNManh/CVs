{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LefCJHKwLB2_"
   },
   "source": [
    "# **OpenCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_6qjhGbgNLO5"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# #Load the image\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# read the image\n",
    "image = cv2.imread('/content/drive/MyDrive/img_cv/faces_2.jpg')\n",
    "image.shape\n",
    "# covert image into gray image\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# face detector\n",
    "face_detector = cv2.CascadeClassifier('/content/drive/MyDrive/haarcascade_frontalface_default.xml')\n",
    "eye_detector = cv2.CascadeClassifier('/content/drive/MyDrive/haarcascade_eye.xml')\n",
    "# check detector is\n",
    "if face_detector.empty():\n",
    "  raise IOError('Unable to load the face cascade classifier xml file')\n",
    "\n",
    "if eye_detector.empty():\n",
    "  raise IOError('Unable to load the eye cascade classifier xml file')\n",
    "\n",
    "# detection face:\n",
    "detections = face_detector.detectMultiScale(gray_image, scaleFactor= 1.06, minNeighbors=3, minSize=(15, 15))\n",
    "eye_detections = eye_detector.detectMultiScale(gray_image, scaleFactor= 1.3, minNeighbors=4, minSize=(3, 3))\n",
    "\n",
    "# draw the dectecte array on image\n",
    "# x, y, w, h are cordinate 4 dimen of dectected array\n",
    "# image: the input image we draw in\n",
    "# (x,y) top-left corner of detected array\n",
    "# (x+w,y+h) bottom-right corner of detected array\n",
    "# (0, 255, 0), 2: green RGB, thickness = 2\n",
    "for (x, y, w, h) in detections:\n",
    "  cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "for (x, y, w, h) in eye_detections:\n",
    "  cv2.rectangle(image, (x, y), (x+w, y+h), (255, 255, 0), 2)\n",
    "cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGpaxcVcK4I7"
   },
   "source": [
    "# **DLib - HOG**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dwc7t43wK6nY"
   },
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eoEMs9mpkZys"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/content/drive/MyDrive/img_cv/test_img/img/faces.jpg')\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "face_detector_hog = dlib.get_frontal_face_detector()\n",
    "\n",
    "# this hog detection not required the input img is gray scale\n",
    "detections = face_detector_hog(image,1)\n",
    "detections\n",
    "for face in detections:\n",
    "  cv2.rectangle(image, (face.left(), face.top()), (face.right(), face.bottom()), (0, 255, 255), 1)\n",
    "\n",
    "cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2n-0G8TZKnuH"
   },
   "source": [
    "# **CNN face detector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8KHXIPz8Kx5F"
   },
   "outputs": [],
   "source": [
    "# Reinstall dlib to ensure compatibility with the current CUDA environment\n",
    "!pip uninstall dlib -y\n",
    "!pip install dlib-bin --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZCE85D3kKtcz"
   },
   "outputs": [],
   "source": [
    "# CNN face detector\n",
    "import dlib\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EFD0VHQ-KJHB"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('/content/drive/MyDrive/img_cv/test_img/img/faces_2.jpg')\n",
    "# Check if the image was loaded successfully\n",
    "if image is None:\n",
    "    raise FileNotFoundError(\"Error loading image. Check the file path.\")\n",
    "\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "face_detector_cnn = dlib.cnn_face_detection_model_v1(\"/content/drive/MyDrive/img_cv/models/mmod_human_face_detector.dat\")\n",
    "# check the detector is exist\n",
    "if face_detector_cnn is None:\n",
    "  raise IOError(\"Unable to load the CNN face detection model\")\n",
    "\n",
    "# The parameters for the face_detector_cnn call are:\n",
    "# image: This is the input image (in this case, the BGR color image loaded by cv2.imread).\n",
    "#        The CNN face detector can work on both color and grayscale images, but it's common\n",
    "#        to use the color image.\n",
    "# 1: This is the 'upsampling' parameter. It indicates how many times to upsample the image\n",
    "#    before running the detector. Upsampling the image can help detect smaller faces,\n",
    "#    but it also increases processing time and memory usage. A value of 1 means the\n",
    "#    image is upsampled once. A value of 0 means no upsampling.\n",
    "detections = face_detector_cnn(image, 1)\n",
    "\n",
    "for face in detections:\n",
    "  l,t,r,b = face.rect.left(), face.rect.top(), face.rect.right(), face.rect.bottom()\n",
    "  cv2.rectangle(image, (l, t), (r, b), (0, 255, 255), 1)\n",
    "  print(face.confidence)\n",
    "\n",
    "cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PA4A_7RKCdk"
   },
   "source": [
    "# **lbph face recognizing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4b46e807"
   },
   "outputs": [],
   "source": [
    "# reinstall the package support for the lbph\n",
    "!pip uninstall opencv-contrib-python -y\n",
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LEYS_tsVKGip"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from google.colab.patches import cv2_imshow\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Egt6cTGHJ6d",
    "outputId": "f5bbdd37-7430-4811-da20-1c0ca108ecd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')\n",
    "folder_path = '/content/drive/MyDrive/img_cv/dataset/archive/'\n",
    "\n",
    "def get_img_data():\n",
    "  paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path)]\n",
    "  ids = []\n",
    "  faces = []\n",
    "  for path in paths:\n",
    "    if os.path.isfile(path) and path.lower().endswith('.gif'):\n",
    "      img = Image.open(path).convert('L') # L is single scale color image\n",
    "      img_np = np.array(img, 'uint8')\n",
    "      id = int(os.path.split(path)[1].split('.')[0].replace('subject',''))\n",
    "      ids.append(id)\n",
    "      faces.append(img_np)\n",
    "\n",
    "  return np.array(ids), faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7G8idtWKM-H"
   },
   "outputs": [],
   "source": [
    "# get the faces and id of the faces\n",
    "ids, faces = get_img_data()\n",
    "\n",
    "\n",
    "# create classifier instance and input training model to output\n",
    "lbph_classifier = cv2.face.LBPHFaceRecognizer_create()\n",
    "lbph_classifier.train(faces, ids)\n",
    "lbph_classifier.write('lbph_classifier.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k1ylDtrZKQOz"
   },
   "outputs": [],
   "source": [
    "# get the sample image\n",
    "test_image = '/content/drive/MyDrive/img_cv/dataset/archive/subject10.sad.gif'\n",
    "\n",
    "image = Image.open(test_image).convert('L')\n",
    "image_np = np.array(image, 'uint8')\n",
    "image_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2aMJV54SKjFw"
   },
   "outputs": [],
   "source": [
    "# using the model to test the sample image\n",
    "prediction = lbph_classifier.predict(image_np)\n",
    "prediction\n",
    "# param 1: id of the subject the model detect\n",
    "# param 2: the confident point, the lower point, the better match\n",
    "#result (3, 0,0)\n",
    "\n",
    "# show the expected output (selected image id)\n",
    "expected_output = int(os.path.split(test_image)[1].split('.')[0].replace('subject',''))\n",
    "expected_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9MASvTjAHqMf"
   },
   "outputs": [],
   "source": [
    "# test for all the sample image in folder\n",
    "paths = [os.path.join('/content/drive/MyDrive/img_cv/dataset/archive', filename) for filename in os.listdir('/content/drive/MyDrive/img_cv/dataset/archive')]\n",
    "predictions = []\n",
    "expected_outputs = []\n",
    "\n",
    "for path in paths:\n",
    "  # Check if the file is a GIF before processing\n",
    "  if os.path.isfile(path) and path.lower().endswith('.gif'):\n",
    "    try:\n",
    "      # image input for test model\n",
    "      image = Image.open(path).convert('L')\n",
    "      image_np = np.array(image, 'uint8')\n",
    "      # using model the get the predicted sample id\n",
    "      prediction, _ = lbph_classifier.predict(image_np)\n",
    "      #\n",
    "      expected_output = int(os.path.split(path)[1].split('.')[0].replace('subject',''))\n",
    "\n",
    "      predictions.append(prediction)\n",
    "      expected_outputs.append(expected_output)\n",
    "    except Exception as e:\n",
    "      print(f\"Error processing file {path}: {e}\")\n",
    "\n",
    "# change result to array\n",
    "predictions = np.array(predictions)\n",
    "expected_outputs = np.array(expected_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GszAoBz6KfPE"
   },
   "outputs": [],
   "source": [
    "# check array of prediction and expected\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(expected_outputs, predictions)\n",
    "accuracy\n",
    "\n",
    "cm = confusion_matrix(expected_outputs, predictions)\n",
    "cm\n",
    "\n",
    "# draw the diagram for result\n",
    "import seaborn\n",
    "\n",
    "seaborn.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWisB9WrEgaa"
   },
   "source": [
    "# **Facial detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mJNXFr-C-o3"
   },
   "outputs": [],
   "source": [
    "# facial detection\n",
    "import dlib\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# detector outline the face\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "# detector for facial\n",
    "point_detector = dlib.shape_predictor('/content/drive/MyDrive/img_cv/models/shape_predictor_68_face_landmarks.dat')\n",
    "#get the test image\n",
    "image =  cv2.imread('/content/drive/MyDrive/img_cv/test_img/img/faces_2.jpg')\n",
    "\n",
    "#input the image to detector\n",
    "face_detection = face_detector(image, 1)\n",
    "\n",
    "for face in face_detection:\n",
    "  # draw the rectangle for each face\n",
    "  l,t,r,b = face.left(), face.top(), face.right(), face.bottom()\n",
    "  cv2.rectangle(image, (l, t), (r, b), (0, 255, 255), 1)\n",
    "\n",
    "  points = point_detector(image, face)\n",
    "  for point in points.parts():\n",
    "    cv2.circle(image, (point.x, point.y), 1, (0, 255, 0), 1)\n",
    "\n",
    "\n",
    "cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Fc85sCzEYiQ"
   },
   "source": [
    "# **Detecting facial descriptor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siTnCnP3Q97s"
   },
   "outputs": [],
   "source": [
    "# Reinstall dlib to ensure compatibility with the current CUDA environment\n",
    "!pip uninstall dlib -y\n",
    "!pip install dlib-bin --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4zQ16nsqJzCm"
   },
   "outputs": [],
   "source": [
    "# import the dependency\n",
    "import os\n",
    "import dlib\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "from PIL import Image\n",
    "from google.colab import drive\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FQ9sUkjgLcgU"
   },
   "outputs": [],
   "source": [
    "# detector outline the face\n",
    "face_detector = dlib.get_frontal_face_detector()\n",
    "# detector for facial\n",
    "point_detector = dlib.shape_predictor('/content/drive/MyDrive/img_cv/models/shape_predictor_68_face_landmarks.dat')\n",
    "#face_description_extractor\n",
    "face_description_extractor = dlib.face_recognition_model_v1('/content/drive/MyDrive/img_cv/models/dlib_face_recognition_resnet_model_v1.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "drwXhS2YMbhl"
   },
   "outputs": [],
   "source": [
    "# execuate the descriptor for the sample data\n",
    "index = {}\n",
    "idx = 0\n",
    "face_descriptors = None\n",
    "\n",
    "paths = [os.path.join('/content/drive/MyDrive/img_cv/dataset/archive', filename) for filename in os.listdir('/content/drive/MyDrive/img_cv/dataset/archive')]\n",
    "for path in paths:\n",
    "  if os.path.isfile(path) and path.lower().endswith('.gif'):\n",
    "    image = Image.open(path).convert('RGB')\n",
    "    image_np = np.array(image, 'uint8')\n",
    "    face_detection = face_detector(image_np, 1)\n",
    "    for face in face_detection:\n",
    "      l,t,r,b = face.left(), face.top(), face.right(), face.bottom()\n",
    "      cv2.rectangle(image_np, (l, t), (r, b), (0, 255, 255), 1)\n",
    "\n",
    "      points = point_detector(image_np, face)\n",
    "      for point in points.parts():\n",
    "        cv2.circle(image_np, (point.x, point.y), 1, (0, 255, 0), 1)\n",
    "\n",
    "      face_descriptor = face_description_extractor.compute_face_descriptor(image_np, points)\n",
    "      # print(len(face_descriptor))\n",
    "\n",
    "      # init and add to the array of face_description\n",
    "      if face_descriptors is None:\n",
    "        face_descriptors = np.array(face_descriptor)\n",
    "      else:\n",
    "        face_descriptors = np.vstack((face_descriptors, np.array(face_descriptor)))\n",
    "\n",
    "      # add index for each face\n",
    "      index[idx] = {path}\n",
    "      idx += 1\n",
    "\n",
    "    # cv2_imshow(image_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E0mPbPcVfDdl"
   },
   "outputs": [],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VjM0Y4MueP5F"
   },
   "outputs": [],
   "source": [
    "# calculate the distance of the faces\n",
    "\n",
    "# Get the path from the set stored in the index\n",
    "image1_path = list(index[45])[0]\n",
    "image2_path = list(index[55])[0]\n",
    "\n",
    "image1 = Image.open(image1_path).convert('RGB')\n",
    "image1_np = np.array(image1, 'uint8')\n",
    "cv2_imshow(image1_np)\n",
    "\n",
    "image2 = Image.open(image2_path).convert('RGB')\n",
    "image2_np = np.array(image2, 'uint8')\n",
    "cv2_imshow(image2_np)\n",
    "\n",
    "np.linalg.norm(face_descriptors[45] - face_descriptors[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2POSqoedh6dU"
   },
   "outputs": [],
   "source": [
    "distances = np.linalg.norm(face_descriptors[45] - face_descriptors, axis=1)\n",
    "idx = 0\n",
    "for distance in distances:\n",
    "  if distance < 0.3:\n",
    "    image = Image.open(list(index[idx])[0])\n",
    "    image_np = np.array(image, 'uint8')\n",
    "    cv2_imshow(image_np)\n",
    "  idx +=1"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
